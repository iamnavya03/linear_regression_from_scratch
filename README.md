ğŸ“Š Linear Regression from Scratch (with Gradient Descent)
This project demonstrates a simple but complete implementation of **Linear Regression from scratch** using **Python and NumPy**, along with a self-generated dataset of _hours studied vs exam score_.
It was created as a part of my journey into understanding the core math and mechanics behind machine learning algorithms.

ğŸš€ What This Project Includes

- âœ”ï¸ Manual implementation of linear regression (no scikit-learn used)
- âœ”ï¸ Gradient descent to minimize the error
- âœ”ï¸ Visualization of the fitted line
- âœ”ï¸ A synthetic dataset (`study_scores_dataset.csv`) with 100 values
- âœ”ï¸ Clean, well-commented Jupyter notebook

ğŸ“‚ Files in This Repository

| File | Description |
|------|-------------|
| `linear_regression_from_scratch.ipynb` | Main Jupyter Notebook containing code, formulas, and explanations |
| `study_scores_dataset.csv` | Dataset used in the project (hours studied vs score) |
| `README.md` | This file |

ğŸ“ˆ Dataset Details

- **Feature (X)**: Hours Studied (random values from 0 to ~12)
- **Target (y)**: Exam Score (0 to 100, with some noise)
- **Total Records**: 100
- Generated using `NumPy` and saved as a CSV

ğŸ§  Key Concepts Learned

- Gradient Descent intuition and implementation
- Loss minimization using RMSE
- Data generation and cleaning
- Plotting predictions vs actual data
- The importance of learning rate and epochs

ğŸ›  Tools Used

- Python 3
- NumPy
- Matplotlib
- Jupyter Notebook
