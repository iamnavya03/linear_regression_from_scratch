📊 Linear Regression from Scratch (with Gradient Descent)
This project demonstrates a simple but complete implementation of **Linear Regression from scratch** using **Python and NumPy**, along with a self-generated dataset of _hours studied vs exam score_.
It was created as a part of my journey into understanding the core math and mechanics behind machine learning algorithms.

🚀 What This Project Includes

- ✔️ Manual implementation of linear regression (no scikit-learn used)
- ✔️ Gradient descent to minimize the error
- ✔️ Visualization of the fitted line
- ✔️ A synthetic dataset (`study_scores_dataset.csv`) with 100 values
- ✔️ Clean, well-commented Jupyter notebook

📂 Files in This Repository

| File | Description |
|------|-------------|
| `linear_regression_from_scratch.ipynb` | Main Jupyter Notebook containing code, formulas, and explanations |
| `study_scores_dataset.csv` | Dataset used in the project (hours studied vs score) |
| `README.md` | This file |

📈 Dataset Details

- **Feature (X)**: Hours Studied (random values from 0 to ~12)
- **Target (y)**: Exam Score (0 to 100, with some noise)
- **Total Records**: 100
- Generated using `NumPy` and saved as a CSV

🧠 Key Concepts Learned

- Gradient Descent intuition and implementation
- Loss minimization using RMSE
- Data generation and cleaning
- Plotting predictions vs actual data
- The importance of learning rate and epochs

🛠 Tools Used

- Python 3
- NumPy
- Matplotlib
- Jupyter Notebook
